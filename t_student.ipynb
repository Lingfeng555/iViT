{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dea7005",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8cad8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.colors as mcolors\n",
    "from experiment_hyperparameters import SPLITS, SIZES\n",
    "\n",
    "from Arquitecture.InformationExtractor import InformationExtractor\n",
    "from experiment_result_processing import  rebuild_model, build_dataset, get_results, plot_and_save_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab122c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_PATH = os.path.expanduser(\"~/Desktop/temp/resultados/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aac10a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ordenador1', 'ordenador2', 'ordenador3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcs = os.listdir(RESULT_PATH)\n",
    "pcs = [dir for dir in pcs if not dir.endswith(\".zip\")]\n",
    "pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea41019",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = {column: [] for column in ['split', 'seed', 'size', 'Precision', 'Recall', 'F1_score', 'Accuracy', 'AUC_ROC']}\n",
    "\n",
    "for dir in pcs:\n",
    "    pc_dir = os.path.join(RESULT_PATH, dir, \"iViT_RESULTS\")\n",
    "    experiments = os.listdir(pc_dir)\n",
    "    experiments.remove(\"experiment_pipeline\")\n",
    "    for experiment in experiments:\n",
    "        experiment_dir = os.path.join(pc_dir, experiment)\n",
    "        splits = os.listdir(experiment_dir)\n",
    "        seed = experiment.split(\"_\")[-1]\n",
    "        for split in splits:\n",
    "            \n",
    "            for i in SIZES:\n",
    "                result_df = pd.read_csv(os.path.join(experiment_dir, split, str(i), \"result.csv\"))\n",
    "                \n",
    "                metrics = result_df.columns.to_list()\n",
    "                metrics.remove(\"Clase\")\n",
    "                \n",
    "                columns = [\"split\", \"seed\", \"size\"]\n",
    "                columns = columns + metrics\n",
    "                    \n",
    "                experiment_results[\"split\"].append(split)\n",
    "                experiment_results[\"seed\"].append(seed)\n",
    "                experiment_results[\"size\"].append(i)\n",
    "                \n",
    "                for metric in metrics:\n",
    "                    experiment_results[metric].append(float(result_df[metric].iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff77b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(experiment_results)\n",
    "df.to_csv(\"seed_dependecy_check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits\n",
      "Precision Mean: 0.5377 ± 0.0796\n",
      "IC 95%: [0.4581, 0.6173]\n",
      "Precision Mean: 0.6989 ± 0.0860\n",
      "IC 95%: [0.6128, 0.7849]\n",
      "Precision Mean: 0.7783 ± 0.0896\n",
      "IC 95%: [0.6887, 0.8679]\n",
      "Precision Mean: 0.7806 ± 0.0819\n",
      "IC 95%: [0.6987, 0.8626]\n",
      "Precision Mean: 0.8543 ± 0.0621\n",
      "IC 95%: [0.7921, 0.9164]\n",
      "Precision Mean: 0.8218 ± 0.0567\n",
      "IC 95%: [0.7651, 0.8785]\n",
      "Precision Mean: 0.7767 ± 0.0945\n",
      "IC 95%: [0.6822, 0.8711]\n",
      "Precision Mean: 0.8459 ± 0.0770\n",
      "IC 95%: [0.7689, 0.9229]\n",
      "Precision Mean: 0.8264 ± 0.0706\n",
      "IC 95%: [0.7559, 0.8970]\n",
      "Precision Mean: 0.8504 ± 0.0728\n",
      "IC 95%: [0.7776, 0.9232]\n",
      "fashion\n",
      "Precision Mean: 0.4998 ± 0.0945\n",
      "IC 95%: [0.4053, 0.5943]\n",
      "Precision Mean: 0.5481 ± 0.0774\n",
      "IC 95%: [0.4707, 0.6256]\n",
      "Precision Mean: 0.5945 ± 0.0546\n",
      "IC 95%: [0.5400, 0.6491]\n",
      "Precision Mean: 0.6255 ± 0.0805\n",
      "IC 95%: [0.5450, 0.7060]\n",
      "Precision Mean: 0.6301 ± 0.0836\n",
      "IC 95%: [0.5466, 0.7137]\n",
      "Precision Mean: 0.6496 ± 0.0814\n",
      "IC 95%: [0.5683, 0.7310]\n",
      "Precision Mean: 0.6946 ± 0.0855\n",
      "IC 95%: [0.6091, 0.7800]\n",
      "Precision Mean: 0.6972 ± 0.0597\n",
      "IC 95%: [0.6375, 0.7569]\n",
      "Precision Mean: 0.6533 ± 0.0695\n",
      "IC 95%: [0.5838, 0.7228]\n",
      "Precision Mean: 0.6875 ± 0.0705\n",
      "IC 95%: [0.6171, 0.7580]\n",
      "balanced\n",
      "Precision Mean: 0.8016 ± 0.0188\n",
      "IC 95%: [0.7829, 0.8204]\n",
      "Precision Mean: 0.5037 ± 0.0315\n",
      "IC 95%: [0.4722, 0.5352]\n",
      "Precision Mean: 0.4841 ± 0.0243\n",
      "IC 95%: [0.4598, 0.5083]\n",
      "Precision Mean: 0.5302 ± 0.0353\n",
      "IC 95%: [0.4949, 0.5655]\n",
      "Precision Mean: 0.4990 ± 0.0290\n",
      "IC 95%: [0.4700, 0.5280]\n",
      "Precision Mean: 0.5783 ± 0.0283\n",
      "IC 95%: [0.5500, 0.6066]\n",
      "Precision Mean: 0.5770 ± 0.0261\n",
      "IC 95%: [0.5509, 0.6030]\n",
      "Precision Mean: 0.5683 ± 0.0245\n",
      "IC 95%: [0.5439, 0.5928]\n",
      "Precision Mean: 0.5783 ± 0.0310\n",
      "IC 95%: [0.5473, 0.6094]\n",
      "Precision Mean: 0.5817 ± 0.0335\n",
      "IC 95%: [0.5483, 0.6152]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(split)\n",
    "    for i in SIZES:\n",
    "        precision_data = df[(df[\"split\"] == split) & (df[\"size\"] == i)].describe()[\"Precision\"]\n",
    "                \n",
    "        # find the mean with a confidence interval of\n",
    "        sample_std = precision_data[\"std\"]\n",
    "        sample_mean = precision_data[\"mean\"]\n",
    "        sample_size = len(df[(df[\"split\"] == split) & (df[\"size\"] == i)])\n",
    "        \n",
    "        alpha = 0.05\n",
    "        t_crit = stats.t.ppf(1 - alpha/2, df=sample_size-1)\n",
    "        sem    = sample_std / np.sqrt(sample_size)\n",
    "        margin = t_crit * sem\n",
    "        lower  = sample_mean - margin\n",
    "        upper  = sample_mean + margin\n",
    "\n",
    "        print(f\"Precision Mean: {sample_mean:.4f} ± {margin:.4f}\")\n",
    "        print(f\"IC 95%: [{lower:.4f}, {upper:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ea689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Asume que df, SPLITS y SIZES ya están definidos:\n",
    "#   SPLITS = df['split'].unique()\n",
    "#   SIZES  = sorted(df['size'].unique())\n",
    "METRICS = ['Precision', 'Recall', 'F1_score', 'Accuracy', 'AUC_ROC']\n",
    "\n",
    "\n",
    "for split in SPLITS:\n",
    "    plt.figure()\n",
    "    for metric in METRICS:\n",
    "        means, lowers, uppers = [], [], []\n",
    "        for size in SIZES:\n",
    "            sub = df[(df['split'] == split) & (df['size'] == size)][metric]\n",
    "            sample_mean = sub.mean()\n",
    "            sample_std  = sub.std(ddof=1)\n",
    "            n           = sub.count()\n",
    "\n",
    "            # IC 95 % de la media\n",
    "            alpha  = 0.05\n",
    "            t_crit = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "            sem    = sample_std / np.sqrt(n)\n",
    "            margin = t_crit * sem\n",
    "\n",
    "            means.append(sample_mean)\n",
    "            lowers.append(sample_mean - margin)\n",
    "            uppers.append(sample_mean + margin)\n",
    "\n",
    "        # Línea de la media y sombreado del IC para esta métrica\n",
    "        plt.plot(SIZES, means, marker='o', label=metric)\n",
    "        plt.fill_between(SIZES, lowers, uppers, alpha=0.2)\n",
    "\n",
    "    plt.xlabel('Size')\n",
    "    plt.ylabel('Metric value')\n",
    "    plt.title(f'With a CI of 95%: {split}')\n",
    "    # Mueve la leyenda fuera, a la derecha\n",
    "    plt.legend(title='Metric', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()  # ajusta para que nada se recorte\n",
    "    plt.savefig(f\"{split}_metrics.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bf11977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>seed</th>\n",
       "      <th>size</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>digits</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994384</td>\n",
       "      <td>0.994375</td>\n",
       "      <td>0.994377</td>\n",
       "      <td>0.998875</td>\n",
       "      <td>0.996875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     split seed  size  Precision    Recall  F1_score  Accuracy   AUC_ROC\n",
       "31  digits    5     2   0.994384  0.994375  0.994377  0.998875  0.996875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Precision\"] == df[df[\"split\"] == \"digits\"][\"Precision\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ee7a550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 360177\n"
     ]
    }
   ],
   "source": [
    "model = rebuild_model(\"digits\", 2, os.path.join(RESULT_PATH, \"ordenador1\", \"iViT_RESULTS\", \"experiment_pipeline_5\", \"digits\", \"2\",\"model.pth\"))\n",
    "test = build_dataset(\"digits\")\n",
    "true, pred , _  = get_results(test, model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total parameters:\", total_params)\n",
    "plot_and_save_confusion_matrix(true, pred, \"best_digits.png\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dd0c0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>seed</th>\n",
       "      <th>size</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>balanced</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857837</td>\n",
       "      <td>0.857819</td>\n",
       "      <td>0.857198</td>\n",
       "      <td>0.99395</td>\n",
       "      <td>0.927364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        split seed  size  Precision    Recall  F1_score  Accuracy   AUC_ROC\n",
       "430  balanced   16     1   0.857837  0.857819  0.857198   0.99395  0.927364"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Precision\"] == df[df[\"split\"] == \"balanced\"][\"Precision\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b43f2b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 343028\n"
     ]
    }
   ],
   "source": [
    "model = rebuild_model(\"balanced\", 1, os.path.join(RESULT_PATH, \"ordenador3\", \"iViT_RESULTS\", \"experiment_pipeline_16\", \"balanced\", \"1\",\"model.pth\"))\n",
    "test = build_dataset(\"balanced\")\n",
    "true, pred , _  = get_results(test, model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total parameters:\", total_params)\n",
    "plot_and_save_confusion_matrix(true, pred, \"best_balanced.png\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93bb9a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>seed</th>\n",
       "      <th>size</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>fashion</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89444</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.893962</td>\n",
       "      <td>0.97872</td>\n",
       "      <td>0.940889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       split seed  size  Precision  Recall  F1_score  Accuracy   AUC_ROC\n",
       "530  fashion   15     1    0.89444  0.8936  0.893962   0.97872  0.940889"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Precision\"] == df[df[\"split\"] == \"fashion\"][\"Precision\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rebuild_model(\"fashion\", 1, os.path.join(RESULT_PATH, \"ordenador3\", \"iViT_RESULTS\", \"experiment_pipeline_15\", \"fashion\", \"1\",\"model.pth\"))\n",
    "fashion_test = build_dataset(\"fashion\")\n",
    "true, pred , _  = get_results(fashion_test, model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total parameters:\", total_params)\n",
    "plot_and_save_confusion_matrix(true, pred, \"best_fashion.png\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee0655d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
